# from hypecheth
import streamlit as st
from utils import st_def, tab_home

st_def.st_logo(title='ğŸ‘‹ Artificial Intelligence! ğŸ¨ ', page_title="AIğŸ¨",)
tab1, tab2, tab3, tab4, tab5 = st.tabs(["General", "Learning ", "Developing Environment", "Developing Process",""])

with tab1: tab_home.home_main_contents()
with tab2: st.markdown('[FastAI Deep Learning](https://course.fast.ai/)',unsafe_allow_html=True)
with tab3: 
    
    
with tab4: 
    st.markdown("""
                1ï¼Œé¢„è®­ç»ƒæ¨¡å‹çš„å®šä¹‰
1.1  æœºå™¨å­¦ä¹ ä¸ºä»€ä¹ˆè¦è®­ç»ƒæ¨¡å‹ï¼Ÿ
ã€€ã€€åœ¨æœºå™¨å­¦ä¹ ä¸­å¤§æ¦‚æœ‰å¦‚ä¸‹æ­¥éª¤ï¼šç¡®å®šæ¨¡å‹ï¼Œè®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨æ¨¡å‹ã€‚

ã€€ã€€æ¨¡å‹ç®€å•æ¥è¯´å¯ä»¥ç†è§£ä¸ºå‡½æ•°ï¼Œç¡®å®šæ¨¡å‹æ—¶è¯´è‡ªå·±è®¤ä¸ºè¿™äº›æ•°æ®çš„ç‰¹å¾ç¬¦åˆå“ªä¸ªå‡½æ•°ã€‚è®­ç»ƒæ¨¡å‹å°±æ˜¯ä½¿ç”¨å·²æœ‰çš„æ•°æ®ï¼Œé€šè¿‡ä¸€äº›æ–¹æ³•ï¼ˆæœ€ä¼˜åŒ–æˆ–è€…å…¶ä»–æ–¹æ³•ï¼‰ç¡®å®šå‡½æ•°çš„å‚æ•°ï¼Œå‚æ•°ç¡®å®šåçš„å‡½æ•°å°±æ˜¯è®­ç»ƒçš„ç»“æœï¼Œä½¿ç”¨æ¨¡å‹å°±æ˜¯å°†æ–°çš„æ•°æ®ä»£å…¥å‡½æ•°æ±‚å€¼ã€‚

ã€€ã€€ä¸€ä¸ªæ¨¡å‹ä¸­ï¼Œæœ‰å¾ˆå¤šå‚æ•°ï¼Œæœ‰äº›å‚æ•°ï¼Œå¯ä»¥é€šè¿‡è®­ç»ƒè·å¾—ï¼Œæ¯”å¦‚logisticæ¨¡å‹ä¸­çš„æƒé‡ã€‚ä½†æ˜¯æœ‰äº›å‚æ•°ï¼Œé€šè¿‡è®­ç»ƒæ— æ³•è·å¾—ï¼Œè¢«ç§°ä¸ºâ€œè¶…å‚æ•°â€ï¼Œæ¯”å¦‚å­¦ä¹ ç‡ç­‰ã€‚è¿™éœ€è¦é ç»éªŒï¼Œè¿‡ç€gird searchçš„æ–¹æ³•å»å¯»æ‰¾ã€‚

1.2  é¢„è®­ç»ƒæ¨¡å‹çš„ç”±æ¥
ã€€ã€€é¢„è®­ç»ƒæ¨¡å‹æ˜¯æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œå·²ç»è¿‡è®­ç»ƒä»¥æ‰§è¡Œå¤§é‡æ•°æ®ä¸Šçš„ç‰¹å®šä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼Œè¯†åˆ«å›¾ç‰‡ä¸Šçš„åˆ†ç±»é—®é¢˜ï¼‰ã€‚è¿™ç§è®­ç»ƒä¸å®¹æ˜“æ‰§è¡Œï¼Œå¹¶ä¸”éœ€è¦å¤§é‡çš„èµ„æºï¼Œè¶…å‡ºè®¸å¤šå¯ç”¨äºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„äººå¯ç”¨çš„èµ„æºã€‚åœ¨è°ˆè®ºé¢„è®­ç»ƒæ¨¡å‹çš„æ—¶å€™ï¼Œé€šå¸¸æŒ‡çš„æ—¶åœ¨ImageNetï¼ˆhttp://image-net.org/ï¼‰ä¸Šè®­ç»ƒçš„CNNï¼ˆç”¨äºè§†è§‰ç›¸å…³ä»»åŠ¡çš„æ¶æ„ï¼‰ã€‚ImageNetæ•°æ®åŒ…å«è¶…è¿‡1400ä¸‡ä¸ªå›¾åƒï¼Œå…¶ä¸­120ä¸‡ä¸ªå›¾åƒåˆ†ä¸º1000ä¸ªç±»åˆ«ï¼ˆå¤§çº¦100ä¸‡ä¸ªå›¾åƒå«è¾¹ç•Œæ¡†å’Œæ³¨é‡Šï¼‰ã€‚

1.3  é¢„è®­ç»ƒæ¨¡å‹çš„å®šä¹‰
ã€€ã€€é¢„è®­ç»ƒæ¨¡å‹æ˜¯åœ¨è®­ç»ƒç»“æŸæ—¶ç»“æœæ¯”è¾ƒå¥½çš„ä¸€ç»„æƒé‡å€¼ï¼Œç ”ç©¶äººå‘˜åˆ†äº«å‡ºæ¥ä¾›å…¶ä»–äººä½¿ç”¨ã€‚æˆ‘ä»¬å¯ä»¥åœ¨GitHubä¸Šæ‰¾åˆ°è®¸å¤šå…·æœ‰æƒé‡çš„åº“ï¼Œä½†æ˜¯åœ¨è·å–é¢„è®­ç»ƒæ¨¡å‹çš„æœ€ç®€å•çš„æ–¹æ³•å¯èƒ½æ˜¯ç›´æ¥æ¥è‡ªä½ é€‰æ‹©çš„æ·±åº¦å­¦ä¹ åº“ã€‚

ã€€ã€€ä¸Šé¢æ˜¯é¢„è®­ç»ƒæ¨¡å‹çš„è§„èŒƒå®šä¹‰ï¼Œä½ è¿˜å¯ä»¥æ‰¾åˆ°é¢„è®­ç»ƒçš„æ¨¡å‹æ¥æ‰§è¡Œå…¶ä»–ä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“æ£€æµ‹æˆ–å§¿åŠ¿ä¼°è®¡ã€‚

ã€€ã€€æ­¤å¤–ï¼Œæœ€è¿‘ç ”ç©¶äººå‘˜å·²å¼€å§‹çªç ´é¢„è®­ç»ƒæ¨¡å‹çš„ç•Œé™ã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆä½¿ç”¨æ–‡æœ¬çš„æ¨¡å‹ï¼‰çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œæˆ‘ä»¬å·²ç»æœ‰ä¸€æ®µæ—¶é—´ä½¿ç”¨åµŒå…¥å±‚ã€‚WordåµŒå…¥æ˜¯ä¸€ç»„æ•°å­—çš„è¡¨ç¤ºï¼Œå…¶ä¸­çš„æƒ³æ³•æ˜¯ç±»ä¼¼çš„å•è¯å°†ä»¥æŸç§æœ‰ç”¨çš„æ–¹å¼è¡¨è¾¾ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›'é¹°æ´¾'ï¼Œ'é¹°'ï¼Œ'è“æ°ä¼Š'çš„è¡¨ç°å½¢å¼æœ‰ä¸€äº›ç›¸ä¼¼ä¹‹å¤„ï¼Œå¹¶ä¸”åœ¨å…¶ä»–æ–¹â€‹â€‹é¢ä¹Ÿæœ‰æ‰€ä¸åŒã€‚ç”¨çŸ¢é‡è¡¨ç¤ºå•è¯çš„å¼€åˆ›æ€§è®ºæ–‡æ˜¯word2vecï¼Œè¿™ç¯‡åµŒå…¥å±‚çš„è®ºæ–‡æ˜¯æˆ‘æœ€å–œæ¬¢çš„è®ºæ–‡ä¹‹ä¸€ï¼Œæœ€æ—©æºäº80å¹´ä»£ï¼ŒGeoffrey Hinton çš„è®ºæ–‡ã€‚

ã€€ã€€å°½ç®¡é€šè¿‡å¯¹å¤§å‹æ•°æ®é›†è¿›è¡Œè®­ç»ƒè·å¾—çš„å•è¯çš„è¡¨ç¤ºéå¸¸æœ‰ç”¨ï¼ˆå¹¶ä¸”ä»¥ä¸é¢„è®­ç»ƒæ¨¡å‹ç±»ä¼¼çš„æ–¹å¼å…±äº«ï¼‰ï¼Œä½†æ˜¯å°†å•è¯åµŒå…¥ä½œä¸ºé¢„è®­ç»ƒæ¨¡å‹ä¼šæœ‰ç‚¹æ‹‰ä¼¸ã€‚ç„¶è€Œï¼Œé€šè¿‡æ°é‡Œç±³éœåå¾·å’Œå¡å·´æ–¯è’‚å®‰é²å¾·çš„å·¥ä½œï¼ŒçœŸæ­£çš„é¢„è®­ç»ƒæ¨¡å‹å·²ç»åˆ°è¾¾NLPä¸–ç•Œã€‚å®ƒä»¬å¾€å¾€éå¸¸å¼ºå¤§ï¼Œå›´ç»•ç€é¦–å…ˆè®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆåœ¨æŸç§æ„ä¹‰ä¸Šç†è§£æŸç§è¯­è¨€ä¸­çš„æ–‡æœ¬è€Œä¸ä»…ä»…æ˜¯å•è¯ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼‰çš„æ¦‚å¿µï¼Œå¹¶å°†å…¶ä½œä¸ºæ›´é«˜çº§ä»»åŠ¡çš„åŸºç¡€ã€‚æœ‰ä¸€ç§éå¸¸å¥½çš„æ–¹æ³•å¯ä»¥åœ¨å¤§é‡æ•°æ®ä¸Šè®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œè€Œä¸éœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œäººå·¥æ³¨é‡Šã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥åœ¨å°½å¯èƒ½å¤šçš„æ•°æ®ä¸Šè®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œæ¯”å¦‚æ•´ä¸ªç»´åŸºç™¾ç§‘ï¼ç„¶åæˆ‘ä»¬å¯ä»¥ä¸ºç‰¹å®šä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼Œæƒ…æ„Ÿåˆ†æï¼‰æ„å»ºåˆ†ç±»å™¨å¹¶å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå…¶ä¸­è·å–æ•°æ®çš„æˆæœ¬æ›´é«˜ã€‚è¦äº†è§£æœ‰å…³è¿™é¡¹éå¸¸æœ‰è¶£çš„å·¥ä½œçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…è®ºæ–‡è™½ç„¶æˆ‘å»ºè®®å…ˆçœ‹çœ‹éšé™„çš„ç½‘ç«™ï¼Œäº†è§£å…¨å±€ã€‚

1.4  ä¸ºä»€ä¹ˆè¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å‘¢ï¼Ÿ
ã€€ã€€ç›®å‰åœ¨æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œä¸­ï¼Œè®­ç»ƒè¿‡ç¨‹æ˜¯åŸºäºæ¢¯åº¦ä¸‹é™æ³•æ¥è¿›è¡Œå‚æ•°è°ƒä¼˜çš„ã€‚é€šè¿‡ä¸€æ­¥æ­¥çš„è¿­ä»£ï¼Œæ¥æ±‚å¾—æœ€å°çš„æŸå¤±å‡½æ•°å’Œæœ€ä¼˜çš„æ¨¡å‹æƒé‡ã€‚è¿›è¡Œæ¢¯åº¦ä¸‹é™æ—¶ç»™æ¯ä¸€ä¸ªå‚æ•°èµ‹ä¸€ä¸ªåˆå§‹å€¼ã€‚ä¸€èˆ¬æˆ‘ä»¬å¸Œæœ›æ•°æ®å’Œå‚æ•°çš„å‡å€¼éƒ½ä¸º0ï¼Œè¾“å…¥å’Œè¾“å‡ºçš„æ–¹æ³•ä¸€è‡´ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå‚æ•°æœä»é«˜æ–¯åˆ†å¸ƒæˆ–è€…å‡åŒ€åˆ†å¸ƒéƒ½æ˜¯æ¯”è¾ƒæœ‰æ•ˆçš„åˆå§‹åŒ–æ–¹æ³•ã€‚

ã€€ã€€æ¨¡å‹çš„ä½œè€…å·²ç»ç»™å‡ºäº†åŸºå‡†æ¨¡å‹ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œæ— éœ€ä»å¤´å¼€å§‹æ„å»ºæ¨¡å‹æ¥è§£å†³ç±»ä¼¼çš„é—®é¢˜ã€‚

ã€€ã€€å°½ç®¡éœ€è¦è¿›è¡Œä¸€äº›å¾®è°ƒï¼Œä½†è¿™ä¸ºæˆ‘ä»¬èŠ‚çœäº†å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚

ã€€ã€€ä¸€ä¸ªå¥½çš„åˆå§‹åŒ–ä¼˜åŠ¿éƒ½æœ‰å“ªäº›å‘¢ï¼Ÿ

1ï¼ŒåŠ é€Ÿæ¢¯åº¦ä¸‹é™çš„æ”¶æ•›é€Ÿåº¦
2ï¼Œæ›´æœ‰å¯èƒ½è·å¾—ä¸€ä¸ªä½æ¨¡å‹è¯¯å·®ï¼Œæˆ–è€…ä½æ³›åŒ–è¯¯å·®çš„æ¨¡å‹
3ï¼Œé™ä½å› æœªåˆå§‹åŒ–æˆ–åˆå§‹åŒ–ä¸å½“å¯¼è‡´çš„æ¢¯åº¦æ¶ˆå¤±æˆ–è€…æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ã€‚æ­¤æƒ…å†µä¼šå¯¼è‡´æ¨¡å‹è®­ç»ƒé€Ÿåº¦å˜æ…¢ï¼Œå´©æºƒï¼Œç›´åˆ°å¤±è´¥
4ï¼Œå…¶ä¸­éšæœºåˆå§‹åŒ–ï¼Œå¯ä»¥æ‰“ç ´å¯¹ç§°æ€§ï¼Œä»è€Œä¿è¯ä¸åŒçš„éšè—å•ä½å¯ä»¥å­¦åˆ°ä¸åŒçš„ä¸œè¥¿ã€‚
1.5  ä»€ä¹ˆæ˜¯finetuningï¼Ÿ
ã€€ã€€finetuningå°±æ˜¯ä½¿ç”¨å·²ç”¨äºå…¶ä»–ç›®æ ‡ï¼Œé¢„è®­ç»ƒå¥½çš„æƒé‡æˆ–è€…éƒ¨åˆ†æƒé‡ï¼Œä½œä¸ºåˆå§‹å€¼å¼€å§‹è®­ç»ƒï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸ç”¨éšæœºé€‰å–çš„å‡ ä¸ªæ•°ä½œä¸ºæƒé‡åˆå§‹å€¼ï¼ŸåŸå› å¾ˆç®€å•ï¼Œç¬¬ä¸€ï¼Œè‡ªå·±ä»å¤´è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œå®¹æ˜“å‡ºç°é—®é¢˜ï¼Œç¬¬äºŒï¼Œfinetuningèƒ½å¾ˆå¿«æ”¶æ•›åˆ°ä¸€ä¸ªè¾ƒç†æƒ³çš„çŠ¶æ€ï¼Œçœæ—¶åˆçœå¿ƒã€‚

ã€€ã€€é‚£ä¹ˆfinetuningçš„å…·ä½“åšæ³•æ˜¯ä»€ä¹ˆï¼Ÿ

å¤ç”¨ç›¸åŒå±‚çš„æƒé‡ï¼Œæ–°å®šä¹‰å±‚å–éšæœºæƒé‡åˆå§‹å€¼
è°ƒå¤§æ–°å®šä¸€å±‚çš„å­¦ä¹ ç‡ï¼Œè°ƒå°æœç”¨å±‚å­¦ä¹ ç‡
1.6  é¢„è®­ç»ƒæ¨¡å‹æœ€å¥½ç»“æœ
ã€€ã€€2018å¹´NLPé¢†åŸŸå–å¾—æœ€é‡å¤§çªç ´ï¼è°·æ­ŒAIå›¢é˜Ÿæ–°å‘å¸ƒçš„BERTæ¨¡å‹ï¼Œåœ¨æœºå™¨é˜…è¯»ç†è§£é¡¶çº§æ°´å¹³æµ‹è¯•SQuAD1.1ä¸­è¡¨ç°å‡ºæƒŠäººçš„æˆç»©ï¼šå…¨éƒ¨ä¸¤ä¸ªè¡¡é‡æŒ‡æ ‡ä¸Šå…¨é¢è¶…è¶Šäººç±»ï¼Œå¹¶ä¸”è¿˜åœ¨11ç§ä¸åŒNLPæµ‹è¯•ä¸­åˆ›å‡ºæœ€ä½³æˆç»©ã€‚æ¯‹åº¸ç½®ç–‘ï¼ŒBERTæ¨¡å‹å¼€å¯äº†NLPçš„æ–°æ—¶ä»£ï¼è€Œè°·æ­Œæå‡ºçš„BERTå°±æ˜¯åœ¨OpenAIçš„GPTçš„åŸºç¡€ä¸Šå¯¹é¢„è®­ç»ƒçš„ç›®æ ‡è¿›è¡Œäº†ä¿®æ”¹ï¼Œå¹¶ç”¨æ›´å¤§çš„æ¨¡å‹ä»¥åŠæ›´å¤šçš„æ•°æ®å»è¿›è¡Œé¢„è®­ç»ƒï¼Œä»è€Œå¾—åˆ°äº†ç›®å‰ä¸ºæ­¢æœ€å¥½çš„æ•ˆæœã€‚

ã€€ã€€æ—æ³¨ï¼šå¦‚ä½•ä»å¤´å¼€å§‹è®­ç»ƒæ¶æ„ä»¥è·å¾—é¢„è®­ç»ƒçš„é‡é‡ï¼Ÿè¿™æ ¹æœ¬ä¸å®¹æ˜“å›ç­”ï¼Œè€Œä¸”ç›¸å…³ä¿¡æ¯ç›¸å½“ç¨€å°‘ã€‚ä»çº¸å¼ åˆ°çº¸å¼ éœ€è¦å¤§é‡çš„è·³è·ƒæ‰èƒ½å°†è®­ç»ƒçš„æ‰€æœ‰æ–¹é¢ï¼ˆå¢å¼ºï¼Œè®­ç»ƒ - æµ‹è¯•åˆ†è£‚ï¼Œé‡é‡è¡°å‡ï¼Œæ—¶é—´è¡¨ç­‰ï¼‰æ‹¼å‡‘åœ¨ä¸€èµ·ã€‚æˆ‘è¯•ç€ç ´è§£å…¶ä¸­ä¸€äº›æˆ‘è¿‡å»åšè¿‡çš„å®éªŒï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œæˆ–è¿™é‡Œçœ‹çœ‹è¿™äº›å°è¯•ã€‚æ›´æœ‰è¶£çš„æ˜¯DAWNBenchæ¯”èµ›ç½‘ç«™ã€‚åœ¨è¿™é‡Œï¼Œå„ä¸ªå›¢é˜Ÿå·²ç»å°è¯•å°†ä»–ä»¬çš„ç¥ç»ç½‘ç»œè®­ç»ƒåˆ°æŸç§ç¨‹åº¦çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶æé«˜èµ„æºä½¿ç”¨æ•ˆç‡å’Œä¼˜åŒ–é€Ÿåº¦ã€‚è¿™é€šå¸¸ä¸æ˜¯æ¶æ„æœ€åˆå¦‚ä½•è®­ç»ƒï¼Œè€Œæ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„ä¿¡æ¯æºï¼ˆå› ä¸ºä»£ç ä¹Ÿå¯ç”¨ï¼‰ã€‚

1.7  TensorFlow VGG-16é¢„è®­ç»ƒæ¨¡å‹
ã€€ã€€å‚è€ƒåšæ–‡ï¼šhttps://blog.csdn.net/daydayup_668819/article/details/70225244

ã€€ã€€åœ¨æˆ‘ä»¬çš„å®é™…é¡¹ç›®ä¸­ï¼Œä¸€èˆ¬ä¸ä¼šç›´æ¥ä»ç¬¬ä¸€å±‚ç›´æ¥å¼€å§‹è®­ç»ƒï¼Œè€Œæ˜¯é€šè¿‡åœ¨å¤§çš„æ•°æ®é›†ä¸Šï¼ˆå¦‚ImageNetï¼‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ŒæŠŠå‰é¢é‚£äº›å±‚çš„å‚æ•°å›ºå®šï¼Œåœ¨è¿ç”¨åˆ°æˆ‘ä»¬æ–°çš„é—®é¢˜ä¸Šï¼Œä¿®æ”¹æœ€åä¸€åˆ°ä¸¤å±‚ï¼Œç”¨è‡ªå·±çš„æ•°æ®å»å¾®è°ƒï¼ˆfinetuningï¼‰ï¼Œä¸€èˆ¬æ•ˆæœä¹Ÿå¾ˆå¥½ã€‚

ã€€ã€€æ‰€è°“finetuningï¼Œå°±æ˜¯è¯´æˆ‘ä»¬é’ˆå¯¹æŸç›¸ä¼¼ä»»åŠ¡å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ¯”å¦‚CaffeNetï¼ŒVGG-16ï¼ŒResNetç­‰ï¼Œå†é€šè¿‡è‡ªå·±çš„æ•°æ®é›†è¿›è¡Œæƒé‡æ›´æ–°ï¼Œå¦‚æœæ•°æ®é‡æ¯”è¾ƒå°ï¼Œå¯ä»¥åªæ›´æ–°æœ€åä¸€å±‚ï¼Œå…¶ä»–å±‚çš„æƒé‡ä¸å˜ï¼Œå¦‚æœæ•°æ®é‡ä¸­ç­‰ï¼Œå¯ä»¥è®­ç»ƒåé¢å‡ å±‚ï¼Œå¦‚æœæ•°æ®é‡å¾ˆå¤§ï¼Œé‚£OKï¼Œç›´æ¥ä»å¤´è®­ç»ƒï¼Œåªä¸è¿‡èŠ±åœ¨è®­ç»ƒçš„æ—¶é—´æ¯”è¾ƒå¤šã€‚

ã€€ã€€åœ¨ç½‘ç»œè®­ç»ƒå¥½ä¹‹åï¼Œåªéœ€è¦forwardè¿‡ç¨‹å°±èƒ½åšé¢„æµ‹ï¼Œå½“ç„¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥æŠŠè¿™ä¸ªç½‘ç»œå½“æˆä¸€ä¸ªfeature extractor æ¥ç”¨ï¼Œå¯ä»¥ç›´æ¥ç”¨ä»»ä½•ä¸€å±‚çš„è¾“å‡ºä½œä¸ºç‰¹å¾ï¼Œæ ¹æ®R-CNNå¯¹AlexNetçš„å®éªŒç»“æœï¼Œå¦‚æœä¸åš fine-tuningï¼Œpool5å’Œfc6å’Œfc7çš„ç‰¹å¾æ•ˆæœå¹¶æ²¡æœ‰å¾ˆå¼ºçš„æå‡ï¼Œæ‰€ä»¥å¦‚æœç›´æ¥ç”¨ä½œfeature extractorï¼Œç›´æ¥ç”¨poolçš„æœ€åä¸€å±‚è¾“å‡ºå°±OKã€‚

ã€€ã€€VGG-16æ˜¯ä¸€ç§æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œ16è¡¨ç¤ºå…¶æ·±åº¦ã€‚æ¨¡å‹å¯ä»¥è¾¾åˆ°92.7%çš„æµ‹è¯•å‡†ç¡®åº¦ï¼Œå®ƒçš„æ•°æ®é›†åŒ…æ‹¬1400ä¸‡å¼ å›¾åƒï¼Œ1000ä¸ªç±»åˆ«ã€‚

2ï¼Œæ¨¡å‹æ–‡æ¡£
ã€€ã€€Kerasçš„åº”ç”¨æ¨¡å—ï¼ˆkeras.applicationsï¼‰æä¾›äº†å¸¦æœ‰é¢„è®­ç»ƒæƒé‡çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥ç”¨æ¥è¿›è¡Œé¢„æµ‹ï¼Œç‰¹å¾æå–å’Œå¾®è°ƒï¼ˆfine-tuningï¼‰ã€‚

2.1  æ¨¡å‹æ¦‚è§ˆ
ã€€ã€€åœ¨ImageNetä¸Šé¢„è®­ç»ƒè¿‡çš„ç”¨äºå›¾åƒåˆ†ç±»çš„æ¨¡å‹ï¼š

Xception
VGG16
VGG19
ResNet, ResNetV2, ResNeXt
InceptionV3
InceptionResNetV2
MobileNet
MobileNetV2
DenseNet
NASNet
ã€€ã€€æ¨¡å‹çš„top-1å‡†ç¡®ç‡å’Œ top-5å‡†ç¡®ç‡åˆ†åˆ«å¦‚ä¸‹ï¼ˆå‡æ˜¯åœ¨ImageNetéªŒè¯é›†ä¸Šçš„ç»“æœï¼‰



 ã€€ã€€ï¼ˆå…¶ä¸­Depth è¡¨ç¤ºç½‘ç»œæ‹“æ‰‘æ·±åº¦ã€‚è¿™åŒ…æ‹¬æ¿€æ´»å±‚ç­‰ï¼‰

ã€€ã€€ä¸‹é¢å¯¹Kerasä¸­å‡ ä¸ªæ¨¡å‹è¿›è¡Œè¯¦ç»†è¯´æ˜ï¼ˆå®˜ç½‘åœ°å€ï¼šhttps://keras-cn.readthedocs.io/en/latest/legacy/other/application/    https://keras.io/zh/applications/ï¼‰

2.2 Xceptionæ¨¡å‹
keras.applications.xception.Xception(include_top=True, 
                                weights='imagenet', input_tensor=None, 
                                input_shape=None, classes=1000)
ã€€ã€€Xception V1æ¨¡å‹ï¼Œæƒé‡ç”± ImageNet è®­ç»ƒè€Œè¨€ï¼Œåœ¨ImageNetä¸Šï¼Œè¯¥æ¨¡å‹å–å¾—äº†éªŒè¯é›† top1  0.790 å’Œ top 5  0.945 çš„æ­£ç¡®ç‡ã€‚

ã€€ã€€æ³¨æ„ï¼Œè¯¥æ¨¡å‹ç›®å‰ä»…èƒ½ä»¥ TensorFlow ä¸ºåç«¯ä½¿ç”¨ï¼Œç”±äºå®ƒä¾èµ–äº â€œSeparable Convolutionâ€å±‚ï¼Œç›®å‰è¯¥æ¨¡å‹åªæ”¯æŒ tf çš„ç»´åº¦é¡ºåºï¼ˆwidthï¼Œheightï¼Œchannelsï¼‰ã€‚

ã€€ã€€é»˜è®¤è¾“å…¥å›¾ç‰‡å¤§å°ä¸º 299*299

ã€€ã€€å‚æ•°ï¼š

include_topï¼šæ˜¯å¦ä¿ç•™é¡¶å±‚çš„3ä¸ªå…¨è¿æ¥ç½‘ç»œ
weightsï¼šNoneä»£è¡¨éšæœºåˆå§‹åŒ–ï¼Œå³ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œâ€œImagenetâ€è¡¨ç¤ºåŠ è½½é¢„è®­ç»ƒæƒé‡
 input_tensorï¼šå¯å¡«å…¥Keras tensor ä½œä¸ºæ¨¡å‹çš„å›¾åƒè¾“å‡º  tensor
input_shapeï¼šå¯é€‰ï¼Œä»…å½“ include_top=False æœ‰æ•ˆï¼Œåº”ä¸ºé•¿ä¸º3çš„ tupleï¼ŒæŒ‡æ˜è¾“å…¥å›¾ç‰‡çš„ shapeï¼Œå›¾ç‰‡çš„å®½é«˜å¿…é¡»å¤§äº 71ï¼Œå¦‚ï¼ˆ150ï¼Œ 150ï¼Œ 3ï¼‰
classesï¼šå¯é€‰ï¼Œå›¾ç‰‡åˆ†ç±»çš„ç±»åˆ«æ•°ï¼Œä»…å½“ include_top=True å¹¶ä¸”ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡æ—¶å¯ç”¨ã€‚
ã€€ã€€è¿”å›å€¼ï¼š

ã€€ã€€Kerasæ¨¡å‹å¯¹è±¡

ã€€ã€€å‚è€ƒæ–‡çŒ®ï¼š

ã€€ã€€https://arxiv.org/abs/1610.02357

2.3 VGG16æ¨¡å‹
keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', 
                                               input_tensor=None, input_shape=None,
                                               classes=1000)
ã€€ã€€vgg16æ¨¡å‹ï¼Œæƒé‡ç”± ImageNet è®­ç»ƒ

ã€€ã€€è¯¥æ¨¡å‹åœ¨ Theanoå’ŒTensorFlowåç«¯å‡å¯ä½¿ç”¨ï¼Œå¹¶æ¥å—thå’Œtfä¸¤ç§è¾“å…¥ç»´åº¦é¡ºåº

ã€€ã€€æ¨¡å‹çš„é»˜è®¤è¾“å…¥å°ºå¯¸ä¸º 224*224

ã€€ã€€å‚æ•°ï¼š

include_topï¼šæ˜¯å¦ä¿ç•™é¡¶å±‚çš„3ä¸ªå…¨è¿æ¥ç½‘ç»œ
weightsï¼šNoneä»£è¡¨éšæœºåˆå§‹åŒ–ï¼Œå³ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œâ€œImagenetâ€è¡¨ç¤ºåŠ è½½é¢„è®­ç»ƒæƒé‡
 input_tensorï¼šå¯å¡«å…¥Keras tensor ä½œä¸ºæ¨¡å‹çš„å›¾åƒè¾“å‡º  tensor
input_shapeï¼šå¯é€‰ï¼Œä»…å½“ include_top=False æœ‰æ•ˆï¼Œåº”ä¸ºé•¿ä¸º3çš„ tupleï¼ŒæŒ‡æ˜è¾“å…¥å›¾ç‰‡çš„ shapeï¼Œå›¾ç‰‡çš„å®½é«˜å¿…é¡»å¤§äº 48ï¼Œå¦‚ï¼ˆ200ï¼Œ 200ï¼Œ 3ï¼‰
poolingï¼šå½“ include_top=Falseæ—¶ï¼Œè¯¥å‚æ•°æŒ‡å®šäº†æ± åŒ–æ–¹å¼ã€‚Noneä»£è¡¨ä¸æ± åŒ–ï¼Œæœ€åä¸€ä¸ªå·ç§¯å±‚çš„è¾“å‡ºä¸º 4Då¼ é‡ï¼Œâ€˜avgâ€™ä»£è¡¨å…¨å±€å¹³å‡æ± åŒ–ï¼Œâ€˜maxâ€™ä»£è¡¨å…¨å±€æœ€å¤§å€¼æ± åŒ–
classesï¼šå¯é€‰ï¼Œå›¾ç‰‡åˆ†ç±»çš„ç±»åˆ«æ•°ï¼Œä»…å½“ include_top=True å¹¶ä¸”ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡æ—¶å¯ç”¨ã€‚
ã€€ã€€è¿”å›å€¼ï¼š

ã€€ã€€Kerasæ¨¡å‹å¯¹è±¡

ã€€ã€€å‚è€ƒæ–‡çŒ®ï¼š

ã€€ã€€https://arxiv.org/abs/1409.1556

2.4 VGG19æ¨¡å‹
keras.applications.vgg19.VGG19(include_top=True, weights='imagenet', 
                                               input_tensor=None, input_shape=None,
                                               classes=1000)
ã€€ã€€vgg19æ¨¡å‹ï¼Œæƒé‡ç”± ImageNet è®­ç»ƒ

ã€€ã€€è¯¥æ¨¡å‹åœ¨ Theanoå’ŒTensorFlowåç«¯å‡å¯ä½¿ç”¨ï¼Œå¹¶æ¥å—thå’Œtfä¸¤ç§è¾“å…¥ç»´åº¦é¡ºåº

ã€€ã€€æ¨¡å‹çš„é»˜è®¤è¾“å…¥å°ºå¯¸ä¸º 224*224

ã€€ã€€å‚æ•°ï¼š

include_topï¼šæ˜¯å¦ä¿ç•™é¡¶å±‚çš„3ä¸ªå…¨è¿æ¥ç½‘ç»œ
weightsï¼šNoneä»£è¡¨éšæœºåˆå§‹åŒ–ï¼Œå³ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œâ€œImagenetâ€è¡¨ç¤ºåŠ è½½é¢„è®­ç»ƒæƒé‡
 input_tensorï¼šå¯å¡«å…¥Keras tensor ä½œä¸ºæ¨¡å‹çš„å›¾åƒè¾“å‡º  tensor
input_shapeï¼šå¯é€‰ï¼Œä»…å½“ include_top=False æœ‰æ•ˆï¼Œåº”ä¸ºé•¿ä¸º3çš„ tupleï¼ŒæŒ‡æ˜è¾“å…¥å›¾ç‰‡çš„ shapeï¼Œå›¾ç‰‡çš„å®½é«˜å¿…é¡»å¤§äº 48ï¼Œå¦‚ï¼ˆ200ï¼Œ 200ï¼Œ 3ï¼‰
poolingï¼šå½“ include_top=Falseæ—¶ï¼Œè¯¥å‚æ•°æŒ‡å®šäº†æ± åŒ–æ–¹å¼ã€‚Noneä»£è¡¨ä¸æ± åŒ–ï¼Œæœ€åä¸€ä¸ªå·ç§¯å±‚çš„è¾“å‡ºä¸º 4Då¼ é‡ï¼Œâ€˜avgâ€™ä»£è¡¨å…¨å±€å¹³å‡æ± åŒ–ï¼Œâ€˜maxâ€™ä»£è¡¨å…¨å±€æœ€å¤§å€¼æ± åŒ–
classesï¼šå¯é€‰ï¼Œå›¾ç‰‡åˆ†ç±»çš„ç±»åˆ«æ•°ï¼Œä»…å½“ include_top=True å¹¶ä¸”ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡æ—¶å¯ç”¨ã€‚
ã€€ã€€è¿”å›å€¼ï¼š

ã€€ã€€Kerasæ¨¡å‹å¯¹è±¡

ã€€ã€€å‚è€ƒæ–‡çŒ®ï¼š

ã€€ã€€https://arxiv.org/abs/1409.1556

ã€€ã€€é¢„è®­ç»ƒæƒé‡ç”±ç‰›æ´¥VGGç»„å‘å¸ƒçš„é¢„è®­ç»ƒæƒé‡ç§»æ¤è€Œæ¥

2.5 ResNet50æ¨¡å‹
keras.applications.resnet50.ResNet50(include_top=True, 
                                weights='imagenet', input_tensor=None, 
                                input_shape=None, classes=1000)
ã€€ã€€50å±‚æ®‹å·®ç½‘ç»œæ¨¡å‹ï¼Œæƒé‡ç”± ImageNet è®­ç»ƒ

ã€€ã€€è¯¥æ¨¡å‹åœ¨Theanoå’ŒTensorFlowåç«¯å‡å¯ä½¿ç”¨ï¼Œå¹¶æ¥å— th å’Œ tfä¸¤ç§è¾“å…¥ç»´åº¦é¡ºåº

ã€€ã€€é»˜è®¤è¾“å…¥å›¾ç‰‡å¤§å°ä¸º 299*299

ã€€ã€€å‚æ•°ï¼š

include_topï¼šæ˜¯å¦ä¿ç•™é¡¶å±‚çš„3ä¸ªå…¨è¿æ¥ç½‘ç»œ
weightsï¼šNoneä»£è¡¨éšæœºåˆå§‹åŒ–ï¼Œå³ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œâ€œImagenetâ€è¡¨ç¤ºåŠ è½½é¢„è®­ç»ƒæƒé‡
 input_tensorï¼šå¯å¡«å…¥Keras tensor ä½œä¸ºæ¨¡å‹çš„å›¾åƒè¾“å‡º  tensor
input_shapeï¼šå¯é€‰ï¼Œä»…å½“ include_top=False æœ‰æ•ˆï¼Œåº”ä¸ºé•¿ä¸º3çš„ tupleï¼ŒæŒ‡æ˜è¾“å…¥å›¾ç‰‡çš„ shapeï¼Œå›¾ç‰‡çš„å®½é«˜å¿…é¡»å¤§äº 71ï¼Œå¦‚ï¼ˆ150ï¼Œ 150ï¼Œ 3ï¼‰
classesï¼šå¯é€‰ï¼Œå›¾ç‰‡åˆ†ç±»çš„ç±»åˆ«æ•°ï¼Œä»…å½“ include_top=True å¹¶ä¸”ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡æ—¶å¯ç”¨ã€‚
ã€€ã€€è¿”å›å€¼ï¼š

ã€€ã€€Kerasæ¨¡å‹å¯¹è±¡

ã€€ã€€å‚è€ƒæ–‡çŒ®ï¼š

ã€€ã€€https://arxiv.org/abs/1512.03385

2.6 Inception V3æ¨¡å‹
keras.applications.inception_v3.InceptionV3(include_top=True, 
                                weights='imagenet', input_tensor=None, 
                                input_shape=None, classes=1000)
ã€€ã€€Inception V3æ¨¡å‹ï¼Œæƒé‡ç”± ImageNet è®­ç»ƒ

ã€€ã€€è¯¥æ¨¡å‹åœ¨ Theanoå’ŒTensorFlowåç«¯å‡å¯ä½¿ç”¨ï¼Œå¹¶æ¥å—th å’Œ tfä¸¤ç§è¾“å…¥ç»´åº¦é¡ºåº

ã€€ã€€é»˜è®¤è¾“å…¥å›¾ç‰‡å¤§å°ä¸º 299*299

ã€€ã€€å‚æ•°ï¼š

include_topï¼šæ˜¯å¦ä¿ç•™é¡¶å±‚çš„3ä¸ªå…¨è¿æ¥ç½‘ç»œ
weightsï¼šNoneä»£è¡¨éšæœºåˆå§‹åŒ–ï¼Œå³ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œâ€œImagenetâ€è¡¨ç¤ºåŠ è½½é¢„è®­ç»ƒæƒé‡
 input_tensorï¼šå¯å¡«å…¥Keras tensor ä½œä¸ºæ¨¡å‹çš„å›¾åƒè¾“å‡º  tensor
input_shapeï¼šå¯é€‰ï¼Œä»…å½“ include_top=False æœ‰æ•ˆï¼Œåº”ä¸ºé•¿ä¸º3çš„ tupleï¼ŒæŒ‡æ˜è¾“å…¥å›¾ç‰‡çš„ shapeï¼Œå›¾ç‰‡çš„å®½é«˜å¿…é¡»å¤§äº 71ï¼Œå¦‚ï¼ˆ150ï¼Œ 150ï¼Œ 3ï¼‰
classesï¼šå¯é€‰ï¼Œå›¾ç‰‡åˆ†ç±»çš„ç±»åˆ«æ•°ï¼Œä»…å½“ include_top=True å¹¶ä¸”ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡æ—¶å¯ç”¨ã€‚
ã€€ã€€è¿”å›å€¼ï¼š

ã€€ã€€Kerasæ¨¡å‹å¯¹è±¡

ã€€ã€€å‚è€ƒæ–‡çŒ®ï¼š

ã€€ã€€https://arxiv.org/abs/1512.00567

2.7 InceptionResNetV2æ¨¡å‹
keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, 
                                weights='imagenet', input_tensor=None, 
                                input_shape=None, pooling=None, classes=1000)
ã€€ã€€Inception-ResNet  V2 æ¨¡å‹ï¼Œæƒé‡ç”± ImageNet è®­ç»ƒ

ã€€ã€€è¯¥æ¨¡å‹åœ¨ Theanoå’ŒTensorFlowåç«¯å‡å¯ä½¿ç”¨ï¼Œå¹¶æ¥å—th å’Œ tfä¸¤ç§è¾“å…¥ç»´åº¦é¡ºåº

ã€€ã€€é»˜è®¤è¾“å…¥å›¾ç‰‡å¤§å°ä¸º 299*299

ã€€ã€€å‚æ•°ï¼š

include_topï¼šæ˜¯å¦ä¿ç•™é¡¶å±‚çš„3ä¸ªå…¨è¿æ¥ç½‘ç»œ
weightsï¼šNoneä»£è¡¨éšæœºåˆå§‹åŒ–ï¼Œå³ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œâ€œImagenetâ€è¡¨ç¤ºåŠ è½½é¢„è®­ç»ƒæƒé‡
 input_tensorï¼šå¯å¡«å…¥Keras tensor ä½œä¸ºæ¨¡å‹çš„å›¾åƒè¾“å‡º  tensor
input_shapeï¼šå¯é€‰ï¼Œä»…å½“ include_top=False æœ‰æ•ˆï¼Œåº”ä¸ºé•¿ä¸º3çš„ tupleï¼ŒæŒ‡æ˜è¾“å…¥å›¾ç‰‡çš„ shapeï¼Œå›¾ç‰‡çš„å®½é«˜å¿…é¡»å¤§äº 71ï¼Œå¦‚ï¼ˆ150ï¼Œ 150ï¼Œ 3ï¼‰
poolingï¼šå¯é€‰ï¼Œå½“ include_topä¸ºFalseæ—¶ï¼Œè¯¥å‚æ•°æŒ‡å®šäº†ç‰¹å¾æå–æ—¶çš„æ± åŒ–æ–¹å¼ã€‚
ã€€ã€€Noneä»£è¡¨ä¸æ± åŒ–ï¼Œç›´æ¥è¾“å‡ºæœ€åä¸€å±‚å·ç§¯å±‚çš„è¾“å‡ºï¼Œè¯¥è¾“å‡ºæ˜¯ä¸€ä¸ªå››ç»´å¼ é‡
ã€€ã€€avg  ä»£è¡¨å…¨å±€å¹³å‡æ± åŒ–ï¼ˆGlobalAveragePooling2Dï¼‰ï¼Œç›¸å½“äºåœ¨æœ€åä¸€å±‚å·ç§¯å±‚åé¢å†åŠ ä¸Šä¸€å±‚å…¨å±€å¹³å‡æ± åŒ–å±‚ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªäºŒç»´å¼ é‡ã€‚
ã€€ã€€max  ä»£è¡¨å…¨å±€æœ€å¤§æ± åŒ–
classesï¼šå¯é€‰ï¼Œå›¾ç‰‡åˆ†ç±»çš„ç±»åˆ«æ•°ï¼Œä»…å½“ include_top=True å¹¶ä¸”ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡æ—¶å¯ç”¨ã€‚
ã€€ã€€è¿”å›å€¼ï¼š

ã€€ã€€Kerasæ¨¡å‹å¯¹è±¡

ã€€ã€€å‚è€ƒæ–‡çŒ®ï¼š

ã€€ã€€https://arxiv.org/abs/1602.07261

2.8  MobileNet æ¨¡å‹
keras.applications.mobilenet.MobileNet(input_shape=None, alpha=1.0, 
                                      depth_multiplier=1, dropout=1e-3, include_top=True, 
                                      weights='imagenet', input_tensor=None, pooling=None, 
                                      classes=1000)
ã€€ã€€Mobilenet æ¨¡å‹ï¼Œæƒé‡ç”± ImageNet è®­ç»ƒ

ã€€ã€€è¯¥æ¨¡å‹åªæ”¯æŒ channels_last çš„ç»´åº¦é¡ºåºï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼Œé€šé“ï¼‰

ã€€ã€€é»˜è®¤è¾“å…¥å›¾ç‰‡å¤§å°ä¸º 224*224

ã€€ã€€å‚æ•°ï¼š

input_shape: å¯é€‰ï¼Œè¾“å…¥å°ºå¯¸å…ƒç»„ï¼Œä»…å½“ include_top=False æ—¶æœ‰æ•ˆï¼Œå¦åˆ™è¾“å…¥å½¢çŠ¶å¿…é¡»æ˜¯ (224, 224, 3)ï¼ˆchannels_last æ ¼å¼ï¼‰æˆ– (3, 224, 224)ï¼ˆchannels_first æ ¼å¼ï¼‰ã€‚å®ƒå¿…é¡»ä¸º 3 ä¸ªè¾“å…¥é€šé“ï¼Œä¸”å®½é«˜å¿…é¡»ä¸å°äº 32ï¼Œæ¯”å¦‚ (200, 200, 3) æ˜¯ä¸€ä¸ªåˆæ³•çš„è¾“å…¥å°ºå¯¸ã€‚
alpha: æ§åˆ¶ç½‘ç»œçš„å®½åº¦ï¼š
å¦‚æœ alpha < 1.0ï¼Œåˆ™åŒæ¯”ä¾‹å‡å°‘æ¯å±‚çš„æ»¤æ³¢å™¨ä¸ªæ•°ã€‚
å¦‚æœ alpha > 1.0ï¼Œåˆ™åŒæ¯”ä¾‹å¢åŠ æ¯å±‚çš„æ»¤æ³¢å™¨ä¸ªæ•°ã€‚
å¦‚æœ alpha = 1ï¼Œä½¿ç”¨è®ºæ–‡é»˜è®¤çš„æ»¤æ³¢å™¨ä¸ªæ•°


depth_multiplier: depthwiseå·ç§¯çš„æ·±åº¦ä¹˜å­ï¼Œä¹Ÿç§°ä¸ºï¼ˆåˆ†è¾¨ç‡ä¹˜å­ï¼‰
dropout: dropout æ¦‚ç‡
include_top: æ˜¯å¦åŒ…æ‹¬é¡¶å±‚çš„å…¨è¿æ¥å±‚ã€‚
weights: None ä»£è¡¨éšæœºåˆå§‹åŒ–ï¼Œ 'imagenet' ä»£è¡¨åŠ è½½åœ¨ ImageNet ä¸Šé¢„è®­ç»ƒçš„æƒå€¼ã€‚
input_tensor: å¯é€‰ï¼ŒKeras tensor ä½œä¸ºæ¨¡å‹çš„è¾“å…¥ï¼ˆæ¯”å¦‚ layers.Input() è¾“å‡ºçš„ tensorï¼‰ã€‚
pooling: å¯é€‰ï¼Œå½“ include_top ä¸º False æ—¶ï¼Œè¯¥å‚æ•°æŒ‡å®šäº†ç‰¹å¾æå–æ—¶çš„æ± åŒ–æ–¹å¼ã€‚
None ä»£è¡¨ä¸æ± åŒ–ï¼Œç›´æ¥è¾“å‡ºæœ€åä¸€å±‚å·ç§¯å±‚çš„è¾“å‡ºï¼Œè¯¥è¾“å‡ºæ˜¯ä¸€ä¸ªå››ç»´å¼ é‡ã€‚
'avg' ä»£è¡¨å…¨å±€å¹³å‡æ± åŒ–ï¼ˆGlobalAveragePooling2Dï¼‰ï¼Œç›¸å½“äºåœ¨æœ€åä¸€å±‚å·ç§¯å±‚åé¢å†åŠ ä¸€å±‚å…¨å±€å¹³å‡æ± åŒ–å±‚ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªäºŒç»´å¼ é‡ã€‚
'max' ä»£è¡¨å…¨å±€æœ€å¤§æ± åŒ–
classes: å¯é€‰ï¼Œå›¾ç‰‡åˆ†ç±»çš„ç±»åˆ«æ•°ï¼Œä»…å½“ include_top ä¸º True å¹¶ä¸”ä¸åŠ è½½é¢„è®­ç»ƒæƒå€¼æ—¶å¯ç”¨ã€‚
ã€€ã€€è¿”å›å€¼ï¼š

ã€€ã€€Kerasæ¨¡å‹å¯¹è±¡

ã€€ã€€å‚è€ƒæ–‡çŒ®ï¼š

ã€€ã€€https://arxiv.org/pdf/1704.04861.pdf

2.9  MusicTaggerCRNNæ¨¡å‹
keras.applications.music_tagger_crnn.MusicTaggerCRNN(weights='msd', 
                                                  input_tensor=None, include_top=True, classes=50)                                                        
ã€€ã€€è¯¥æ¨¡å‹æ˜¯ä¸€ä¸ªå·ç§¯å¾ªç¯æ¨¡å‹ï¼Œä»¥å‘é‡åŒ–çš„ MelSpectrogram éŸ³ä¹æ•°æ®ä¸ºè¾“å…¥ï¼Œèƒ½å¤Ÿè¾“å‡ºéŸ³ä¹çš„é£æ ¼ã€‚ä½ å¯ä»¥ç”¨ keras.applications.musiic_tagger_crnn.preprocess_input æ¥å°†ä¸€ä¸ªéŸ³ä¹æ–‡ä»¶å‘é‡åŒ–ä¸º spectrogramï¼Œæ³¨æ„ï¼Œä½¿ç”¨è¯¥åŠŸèƒ½éœ€è¦å®‰è£… Librosaï¼Œè¯·å‚è€ƒä»¥ä¸‹ä½¿ç”¨èŒƒä¾‹ã€‚

ã€€ã€€å‚æ•°ï¼š

include_topï¼šæ˜¯å¦ä¿ç•™é¡¶å±‚çš„3ä¸ªå…¨è¿æ¥ç½‘ç»œ
weightsï¼šNoneä»£è¡¨éšæœºåˆå§‹åŒ–ï¼Œå³ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œâ€œmsd" ä»£è¡¨åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆè®­ç»ƒè‡ªMillon Song DataSetï¼šhttp://labrosa.ee.columbia.edu/millionsong/ï¼‰
 input_tensorï¼šå¯å¡«å…¥Keras tensor ä½œä¸ºæ¨¡å‹çš„å›¾åƒè¾“å‡º  tensor
input_shapeï¼šå¯é€‰ï¼Œä»…å½“ include_top=False æœ‰æ•ˆï¼Œåº”ä¸ºé•¿ä¸º3çš„ tupleï¼ŒæŒ‡æ˜è¾“å…¥å›¾ç‰‡çš„ shapeï¼Œå›¾ç‰‡çš„å®½é«˜å¿…é¡»å¤§äº 71ï¼Œå¦‚ï¼ˆ150ï¼Œ 150ï¼Œ 3ï¼‰
classesï¼šå¯é€‰ï¼Œå›¾ç‰‡åˆ†ç±»çš„ç±»åˆ«æ•°ï¼Œä»…å½“ include_top=True å¹¶ä¸”ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡æ—¶å¯ç”¨ã€‚
ã€€ã€€è¿”å›å€¼ï¼š

ã€€ã€€Kerasæ¨¡å‹å¯¹è±¡

ã€€ã€€å‚è€ƒæ–‡çŒ®ï¼š

ã€€ã€€https://arxiv.org/abs/1609.04243

ã€€ã€€ä½¿ç”¨èŒƒä¾‹ï¼šéŸ³ä¹ç‰¹å¾æŠ½å–ä¸é£æ ¼æ ‡å®š

from keras.applications.music_tagger_crnn import MusicTaggerCRNN
from keras.applications.music_tagger_crnn import preprocess_input, decode_predictions
import numpy as np

# 1. Tagging
model = MusicTaggerCRNN(weights='msd')

audio_path = 'audio_file.mp3'
melgram = preprocess_input(audio_path)
melgrams = np.expand_dims(melgram, axis=0)

preds = model.predict(melgrams)
print('Predicted:')
print(decode_predictions(preds))
# print: ('Predicted:', [[('rock', 0.097071797), ('pop', 0.042456303), ('alternative', 0.032439161), ('indie', 0.024491295), ('female vocalists', 0.016455274)]])

#. 2. Feature extraction
model = MusicTaggerCRNN(weights='msd', include_top=False)

audio_path = 'audio_file.mp3'
melgram = preprocess_input(audio_path)
melgrams = np.expand_dims(melgram, axis=0)

feats = model.predict(melgrams)
print('Features:')
print(feats[0, :10])
# print: ('Features:', [-0.19160545 0.94259131 -0.9991011 0.47644514 -0.19089699 0.99033844 0.1103896 -0.00340496 0.14823607 0.59856361])
ã€€ã€€

3ï¼Œå›¾ç‰‡åˆ†ç±»æ¨¡å‹çš„ç¤ºä¾‹
ã€€ã€€åº”ç”¨äºå›¾åƒåˆ†ç±»çš„æ¨¡å‹ï¼Œæƒé‡è®­ç»ƒè‡ª ImageNetï¼šXception  VGG16   VGG19  ResNet50 InceptionV3

ã€€ã€€æ‰€æœ‰çš„è¿™äº›æ¨¡å‹ï¼ˆé™¤äº†Xceptionï¼‰éƒ½å…¼å®¹ Theano å’Œ TensorFlowï¼Œå¹¶ä¼šè‡ªåŠ¨åŸºäº ~/.keras/keras.json çš„Keras çš„å›¾åƒç»´åº¦è¿›è¡Œè‡ªåŠ¨è®¾ç½®ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ è®¾ç½® data_format = 'channel_last'ï¼Œåˆ™åŠ è½½çš„æ¨¡å‹å°†æŒ‰ç…§ TensorFlowçš„ç»´åº¦é¡ºåºæ¥æ„é€ ï¼Œå³â€œWidth-Height-Depthâ€çš„é¡ºåºã€‚

3.1  åˆ©ç”¨ResNet50 ç½‘ç»œè¿›è¡Œ ImageNetåˆ†ç±»
ã€€ã€€ä»£ç å¦‚ä¸‹ï¼š

# åˆ©ç”¨ResNet50ç½‘ç»œè¿›è¡Œ ImageNet åˆ†ç±»
from keras.applications.resnet50 import ResNet50
from keras.preprocessing import image
from keras.applications.resnet50 import preprocess_input, decode_predictions
import numpy as np

model = ResNet50(weights='imagenet')

img_path = 'elephant.jpg'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

preds = model.predict(x)
# decode the results into a list of tuples(class description, probability)
# one such list for each sample in the batch
print('Predicted:', decode_predictions(preds, top=3)[0])
'''
Predicted: [('n01871265', 'tusker', 0.40863296), 
('n02504458', 'African_elephant', 0.36055887), 
('n02504013', 'Indian_elephant', 0.22416794)]
'''
ã€€ã€€

3.2  åˆ©ç”¨ VGG16 æå–ç‰¹å¾
ã€€ã€€ä»£ç å¦‚ä¸‹ï¼š

# åˆ©ç”¨VGG16æå–ç‰¹å¾
from keras.applications.vgg16 import VGG16
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input
import numpy as np

model = VGG16(weights='imagenet', include_top=False)

img_path = 'elephant.jpg'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

features = model.predict(x)
print(features.shape, type(features))
# (1, 7, 7, 512) <class 'numpy.ndarray'>
ã€€ã€€

3.3  ä» VGG19çš„ä»»æ„ä¸­é—´å±‚ä¸­æŠ½å–ç‰¹å¾
ã€€ã€€ä»£ç å¦‚ä¸‹ï¼š

# åˆ©ç”¨VGG19æå–ç‰¹å¾
from keras.applications.vgg19 import VGG19
from keras.preprocessing import image
from keras.applications.vgg19 import preprocess_input
from keras.models import Model
import numpy as np

base_model = VGG19(weights='imagenet')
model = Model(inputs=base_model.input,
              outputs=base_model.get_layer('block4_pool').output)

img_path = 'elephant.jpg'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

block4_pool_features = model.predict(x)
print(block4_pool_features.shape, type(block4_pool_features))
ã€€ã€€æ³¨æ„ï¼Œè¿™é‡Œå°†æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œå°±ä¸ç”¨äº†å…ˆåŠ è½½ç½‘ä¸Šçš„æ¨¡å‹äº†ï¼Œè¿™æ ·æ¯”è¾ƒå¿«ï¼Œä¸‹è½½åˆ°æœ¬åœ°ï¼Œç„¶åä¿®æ”¹æºç è·¯å¾„å³å¯



 

3.4  åœ¨æ–°ç±»ä¸Š finetune  inceptionV3
ã€€ã€€ä»£ç å¦‚ä¸‹ï¼š

from keras.applications.inception_v3 import InceptionV3
from keras.preprocessing import image
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from keras import backend as K

# create the base pre-trained model
base_model = InceptionV3(weights='imagenet', include_top=False)

# add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)
# let's add a fully-connected layer
x = Dense(1024, activation='relu')(x)
# and a logistic layer -- let's say we have 200 classes
predictions = Dense(200, activation='softmax')(x)

# this is the model we will train
model = Model(input=base_model.input, output=predictions)

# first: train only the top layers (which were randomly initialized)
# i.e. freeze all convolutional InceptionV3 layers
for layer in base_model.layers:
    layer.trainable = False

# compile the model (should be done *after* setting layers to non-trainable)
model.compile(optimizer='rmsprop', loss='categorical_crossentropy')

# train the model on the new data for a few epochs
model.fit_generator(...)

# at this point, the top layers are well trained and we can start fine-tuning
# convolutional layers from inception V3. We will freeze the bottom N layers
# and train the remaining top layers.

# let's visualize layer names and layer indices to see how many layers
# we should freeze:
for i, layer in enumerate(base_model.layers):
   print(i, layer.name)

# we chose to train the top 2 inception blocks, i.e. we will freeze
# the first 172 layers and unfreeze the rest:
for layer in model.layers[:172]:
   layer.trainable = False
for layer in model.layers[172:]:
   layer.trainable = True

# we need to recompile the model for these modifications to take effect
# we use SGD with a low learning rate
from keras.optimizers import SGD
model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')

# we train our model again (this time fine-tuning the top 2 inception blocks
# alongside the top Dense layers
model.fit_generator(...)
ã€€ã€€

3.5  åœ¨å®šåˆ¶çš„è¾“å…¥ tensor ä¸Šæ„å»º Inception V3
ã€€ã€€ä»£ç å¦‚ä¸‹ï¼š

from keras.applications.inception_v3 import InceptionV3
from keras.layers import Input

# this could alse be the output a different Keras model or layer
input_tensor = Input(shape=(224, 224, 3))
model = InceptionV3(input_tensor=input_tensor,
                    weights='imagenet',
                    include_top=True)
'''
Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5
'''
ã€€ã€€

4ï¼Œæ¨¡å‹è¯´æ˜
4.1  thä¸tf çš„åŒºåˆ«
ã€€ã€€Kerasæä¾›äº†ä¸¤å¥—åç«¯ï¼ŒTheano å’Œ TensorFlowï¼Œtfå’Œth çš„å¤§éƒ¨åˆ†åŠŸèƒ½éƒ½è¢« backend ç»Ÿä¸€åŒ…è£…èµ·æ¥äº†ï¼Œä½†æ˜¯äºŒè€…è¿˜æ˜¯å­˜åœ¨ä¸å°‘çš„å†²çªï¼Œæœ‰æ—¶å€™éœ€è¦ç‰¹åˆ«æ³¨æ„Kerasæ˜¯è¿è¡Œåœ¨å“ªç§åç«¯ä¸Šï¼Œä»–ä»¬çš„ä¸»è¦å†²çªæ˜¯ç»´åº¦é¡ºåºï¼Œä¹Ÿå°±æ˜¯æ•°æ®æ ¼å¼çš„åŒºåˆ«ï¼Œchannels_last å¯¹åº”çš„æ˜¯ tfï¼Œchannels_first å¯¹åº”çš„æ˜¯ thã€‚

ã€€ã€€æ¯”å¦‚ï¼š

vgg16_weights_th_dim_ordering_th_kernels_notop.h5 
vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5 
ã€€ã€€

4.2  notopæ¨¡å‹æ˜¯æŒ‡ä»€ä¹ˆï¼Ÿ
ã€€ã€€notop è¡¨ç¤ºæ˜¯å¦åŒ…å«æœ€åä¸‰ä¸ªå…¨è¿æ¥å±‚ï¼ˆwhether to include the 3 fully-connected layers at the top of the networkï¼‰ï¼Œç”¨æ¥åš fine-tuning ä¸“ç”¨ï¼Œä¸“é—¨å¼€æºäº†è¿™ç±»æ¨¡å‹ã€‚

ã€€ã€€å°±æ¯”å¦‚ä¸Šé¢æ¨¡å‹ä¸­å‡ºç°çš„ include_top=False/Trueï¼Œä¸€èˆ¬æ¥è¯´ä¸ºTRUEï¼Œè¡¨ç¤ºä¿ç•™é¡¶å±‚çš„å…¨è¿æ¥ç½‘ç»œã€‚

4.3  H5pyç®€è¿°
ã€€ã€€Kerasä¸­å·²è®­ç»ƒæ¨¡å‹ä¸ºH5PY æ ¼å¼çš„ï¼Œä¸æ˜¯ caffe çš„ .caffemodel

ã€€ã€€htpy.File ç±»ä¼¼äºPythonçš„è¯å…¸å¯¹è±¡ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹æ‰€æœ‰çš„é”®å€¼ã€‚

ã€€ã€€è¯»å…¥å¦‚ä¸‹ï¼š

# è¯»å…¥æ¨¡å‹
file=h5py.File('.../notop.h5','r')

# ä»£è¡¨fileçš„å±æ€§ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªå±æ€§ä¸º 'nb_layers'
file.attrs['nb_layers']

f.keys()
[u'block1_conv1', u'block1_conv2', u'block1_pool', u'block2_conv1', u'block2_conv2', 
u'block2_pool', u'block3_conv1', u'block3_conv2', u'block3_conv3', u'block3_pool', 
u'block4_conv1', u'block4_conv2', u'block4_conv3', u'block4_pool', u'block5_conv1', 
u'block5_conv2', u'block5_conv3', u'block5_pool']
ã€€ã€€å¯ä»¥ä½¿ç”¨ä¸‹é¢ä»£ç çœ‹fileä¸­å„ä¸ªå±‚å†…æœ‰ä»€ä¹ˆ

for name in file:
    print(name)
    # ç±»ä¼¼f.keys()
ã€€ã€€ç»“æœå¦‚ä¸‹ï¼š

block1_conv1
block1_conv2
block1_pool
block2_conv1
block2_conv2
block2_pool
block3_conv1
block3_conv2
block3_conv3
block3_pool
block4_conv1
block4_conv2
block4_conv3
block4_pool
block5_conv1
block5_conv2
block5_conv3
block5_pool
ã€€ã€€

5ï¼ŒKeras-application-VGG16è§£è¯»
ã€€ã€€æ³¨æ„ï¼šåœ¨è®¡ç®—æœºè§†è§‰CVä»»åŠ¡ä¸­ï¼Œå¯¹äºè¿œå¤§äºå¯ç”¨å†…å­˜çš„å¤§å‹å›¾ç‰‡æ•°æ®é›†ï¼Œåº”ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ VGG16 æå– bottleneckç‰¹å¾ï¼Œç”¨ HDF5ä¿å­˜ç‰¹å¾ arrayï¼Œæ˜¯ç›®å‰æˆ‘æ„Ÿè§‰çš„æœ€ä½³æ–¹æ¡ˆã€‚

5.1 å‡½æ•°å¼
ã€€ã€€æ­¤pyæ–‡ä»¶æ¥æºäºï¼šhttps://github.com/fchollet/deep-learning-models/blob/master/vgg16.py

ã€€ã€€æ­¤è§£è¯»æ–‡ä»¶æ¥æºäºï¼šhttps://blog.csdn.net/sinat_26917383/article/details/72859145

ã€€ã€€VGG16é»˜è®¤çš„è¾“å…¥æ•°æ®æ ¼å¼åº”è¯¥æ˜¯ï¼šchannels_last

ã€€ã€€ä»£ç å¦‚ä¸‹ï¼š

# -*- coding: utf-8 -*-
'''VGG16 model for Keras.
# Reference:
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)
'''
from __future__ import print_function

import numpy as np
import warnings

from keras.models import Model
from keras.layers import Flatten
from keras.layers import Dense
from keras.layers import Input
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import GlobalMaxPooling2D
from keras.layers import GlobalAveragePooling2D
from keras.preprocessing import image
from keras.utils import layer_utils
from keras.utils.data_utils import get_file
from keras import backend as K
from keras.applications.imagenet_utils import decode_predictions
# decode_predictions è¾“å‡º5ä¸ªæœ€é«˜æ¦‚ç‡ï¼š(ç±»å, è¯­ä¹‰æ¦‚å¿µ, é¢„æµ‹æ¦‚ç‡) decode_predictions(y_pred)
from keras.applications.imagenet_utils import preprocess_input
#  é¢„å¤„ç† å›¾åƒç¼–ç æœä»è§„å®šï¼Œè­¬å¦‚,RGBï¼ŒGBRè¿™ä¸€ç±»çš„ï¼Œpreprocess_input(x)  
from keras.applications.imagenet_utils import _obtain_input_shape
# ç¡®å®šé€‚å½“çš„è¾“å…¥å½¢çŠ¶ï¼Œç›¸å½“äºopencvä¸­çš„read.imgï¼Œå°†å›¾åƒå˜ä¸ºæ•°ç»„
from keras.engine.topology import get_source_inputs

WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'
WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'

def VGG16(include_top=True, weights='imagenet',
          input_tensor=None, input_shape=None,
          pooling=None,
          classes=1000):
    # æ£€æŸ¥weightä¸åˆ†ç±»è®¾ç½®æ˜¯å¦æ­£ç¡®
    if weights not in {'imagenet', None}:
        raise ValueError('The `weights` argument should be either '
                         '`None` (random initialization) or `imagenet` '
                         '(pre-training on ImageNet).')

    if weights == 'imagenet' and include_top and classes != 1000:
        raise ValueError('If using `weights` as imagenet with `include_top`'
                         ' as true, `classes` should be 1000')

    # è®¾ç½®å›¾åƒå°ºå¯¸ï¼Œç±»ä¼¼caffeä¸­çš„transform
    # Determine proper input shape
    input_shape = _obtain_input_shape(input_shape,
                                      default_size=224,
                                      min_size=48,
                                      # æ¨¡å‹æ‰€èƒ½æ¥å—çš„æœ€å°é•¿å®½
                                      data_format=K.image_data_format(),
                                      # æ•°æ®çš„ä½¿ç”¨æ ¼å¼
                                      include_top=include_top)
                                      #æ˜¯å¦é€šè¿‡ä¸€ä¸ªFlattenå±‚å†è¿æ¥åˆ°åˆ†ç±»å™¨

    # æ•°æ®ç®€å•å¤„ç†ï¼Œresize
    if input_tensor is None:
        img_input = Input(shape=input_shape)
        # è¿™é‡Œçš„Inputæ˜¯kerasçš„æ ¼å¼ï¼Œå¯ä»¥ç”¨äºè½¬æ¢
    else:
        if not K.is_keras_tensor(input_tensor):
            img_input = Input(tensor=input_tensor, shape=input_shape)
        else:
            img_input = input_tensor
        # å¦‚æœæ˜¯tensorçš„æ•°æ®æ ¼å¼ï¼Œéœ€è¦ä¸¤æ­¥èµ°ï¼š
        # å…ˆåˆ¤æ–­æ˜¯å¦æ˜¯kerasæŒ‡å®šçš„æ•°æ®ç±»å‹ï¼Œis_keras_tensor
        # ç„¶åget_source_inputs(input_tensor)

    # ç¼–å†™ç½‘ç»œç»“æ„ï¼Œprototxt
    # Block 1
    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)
    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)

    # Block 2
    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)
    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)

    # Block 3
    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)
    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)
    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)

    # Block 4
    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)
    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)
    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)

    # Block 5
    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)
    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)
    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)

    if include_top:
        # Classification block
        x = Flatten(name='flatten')(x)
        x = Dense(4096, activation='relu', name='fc1')(x)
        x = Dense(4096, activation='relu', name='fc2')(x)
        x = Dense(classes, activation='softmax', name='predictions')(x)
    else:
        if pooling == 'avg':
            x = GlobalAveragePooling2D()(x)
        elif pooling == 'max':
            x = GlobalMaxPooling2D()(x)

    # è°ƒæ•´æ•°æ®      
    # Ensure that the model takes into account
    # any potential predecessors of `input_tensor`.
    if input_tensor is not None:
        inputs = get_source_inputs(input_tensor)
        # get_source_inputs è¿”å›è®¡ç®—éœ€è¦çš„æ•°æ®åˆ—è¡¨ï¼ŒList of input tensors.
        # å¦‚æœæ˜¯tensorçš„æ•°æ®æ ¼å¼ï¼Œéœ€è¦ä¸¤æ­¥èµ°ï¼š
        # å…ˆåˆ¤æ–­æ˜¯å¦æ˜¯kerasæŒ‡å®šçš„æ•°æ®ç±»å‹ï¼Œis_keras_tensor
        # ç„¶åget_source_inputs(input_tensor)
    else:
        inputs = img_input

    # åˆ›å»ºæ¨¡å‹
    # Create model.
    model = Model(inputs, x, name='vgg16')

    # åŠ è½½æƒé‡
    # load weights
    if weights == 'imagenet':
        if include_top:
            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',
                                    WEIGHTS_PATH,
                                    cache_subdir='models')
        else:
            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',
                                    WEIGHTS_PATH_NO_TOP,
                                    cache_subdir='models')
        model.load_weights(weights_path)

        if K.backend() == 'theano':
            layer_utils.convert_all_kernels_in_model(model)

        if K.image_data_format() == 'channels_first':
            if include_top:
                maxpool = model.get_layer(name='block5_pool')
                shape = maxpool.output_shape[1:]
                dense = model.get_layer(name='fc1')
                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')

            if K.backend() == 'tensorflow':
                warnings.warn('You are using the TensorFlow backend, yet you '
                              'are using the Theano '
                              'image data format convention '
                              '(`image_data_format="channels_first"`). '
                              'For best performance, set '
                              '`image_data_format="channels_last"` in '
                              'your Keras config '
                              'at ~/.keras/keras.json.')
    return model

if __name__ == '__main__':
    model = VGG16(include_top=True, weights='imagenet')

    img_path = 'elephant.jpg'
    img = image.load_img(img_path, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    print('Input image shape:', x.shape)

    preds = model.predict(x)
    print('Predicted:', decode_predictions(preds))
    # decode_predictions è¾“å‡º5ä¸ªæœ€é«˜æ¦‚ç‡ï¼š(ç±»å, è¯­ä¹‰æ¦‚å¿µ, é¢„æµ‹æ¦‚ç‡)
ã€€ã€€1ï¼Œå°†æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œä¸å¿…æ¯æ¬¡ä»ç½‘ç«™è¿›è¡ŒåŠ è½½

ã€€ã€€å½“æ¨¡å‹ä¸‹è½½å¥½äº†ï¼Œå°±å¯ä»¥ä¿®æ”¹ä»¥ä¸‹å†…å®¹ï¼š

WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'
                'releases/download/v0.1/'
                'vgg19_weights_tf_dim_ordering_tf_kernels.h5')
WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'
                       'releases/download/v0.1/'
                       'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')

# Load weights.
    if weights == 'imagenet':
        if include_top:
            weights_path = keras_utils.get_file(
                'vgg19_weights_tf_dim_ordering_tf_kernels.h5',
                WEIGHTS_PATH,
                cache_subdir='models',
                file_hash='cbe5617147190e668d6c5d5026f83318')
        else:
            weights_path = keras_utils.get_file(
                'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',
                WEIGHTS_PATH_NO_TOP,
                cache_subdir='models',
                file_hash='253f8cb515780f3b799900260a226db6')
        model.load_weights(weights_path)
        if backend.backend() == 'theano':
            keras_utils.convert_all_kernels_in_model(model)
    elif weights is not None:
        model.load_weights(weights)
ã€€ã€€2ï¼Œå‡ ä¸ªlayerä¸­çš„æ–°ç”¨æ³•

from keras.applications.imagenet_utils import decode_predictions
decode_predictions è¾“å‡º5ä¸ªæœ€é«˜æ¦‚ç‡ï¼š(ç±»å, è¯­ä¹‰æ¦‚å¿µ, é¢„æµ‹æ¦‚ç‡) decode_predictions(y_pred)

from keras.applications.imagenet_utils import preprocess_input
é¢„å¤„ç† å›¾åƒç¼–ç æœä»è§„å®šï¼Œè­¬å¦‚,RGBï¼ŒGBRè¿™ä¸€ç±»çš„ï¼Œpreprocess_input(x)  

from keras.applications.imagenet_utils import _obtain_input_shape 
ç¡®å®šé€‚å½“çš„è¾“å…¥å½¢çŠ¶ï¼Œç›¸å½“äºopencvä¸­çš„read.imgï¼Œå°†å›¾åƒå˜ä¸ºæ•°ç»„
ï¼ˆ1ï¼‰decode_predictionsç”¨åœ¨æœ€åè¾“å‡ºç»“æœä¸Šï¼Œæ¯”è¾ƒå¥½ç”¨ã€print(â€˜Predicted:â€™, decode_predictions(preds))ã€‘ï¼›
ï¼ˆ2ï¼‰preprocess_inputï¼Œæ”¹å˜ç¼–ç ï¼Œã€preprocess_input(x)ã€‘ï¼›
ï¼ˆ3ï¼‰_obtain_input_shape
ã€€ã€€3ï¼Œå½“inclide_top=True æ—¶

fc_model = VGG16(include_top=True)
notop_model = VGG16(include_top=False)
ã€€ã€€å½“ä½¿ç”¨VGG16åš fine-tuning çš„æ—¶å€™ï¼Œå¾—åˆ°çš„ notop_model å°±æ˜¯æ²¡æœ‰å…¨è¿æ¥å±‚çš„æ¨¡å‹ï¼Œç„¶åå†å»æ·»åŠ è‡ªå·±çš„å±‚ã€‚

ã€€ã€€å½“æ˜¯å¥å…¨çš„ç½‘ç»œç»“æ„çš„æ—¶å€™ï¼Œfc_modeléœ€è¦æ·»åŠ ä»¥ä¸‹çš„å†…å®¹ä»¥è¡¥å…¨ç½‘ç»œç»“æ„ï¼š

x = Flatten(name='flatten')(x)
x = Dense(4096, activation='relu', name='fc1')(x)
x = Dense(4096, activation='relu', name='fc2')(x)
x = Dense(classes, activation='softmax', name='predictions')(x)
ã€€ã€€poolå±‚ä¹‹åæ¥ä¸€ä¸ª flattenå±‚ï¼Œä¿®æ”¹æ•°æ®æ ¼å¼ï¼Œç„¶åæ¥ä¸¤ä¸ª denseå±‚ï¼Œæœ€åæœ‰softmaxçš„denseå±‚ã€‚

ã€€ã€€4ï¼Œå¦‚æœè¾“å…¥çš„æ•°æ®æ ¼å¼æ˜¯ channels_first

ã€€ã€€å…¶å®æˆ‘éƒ½é»˜è®¤æ˜¯ä½¿ç”¨TensorFlowåç«¯ï¼Œæ‰€ä»¥æ•°æ®æ ¼å¼ä¸€èˆ¬æ˜¯ channels_lastï¼Œä½†æ˜¯å¦‚æœinputæ ¼å¼æ˜¯â€œchannels_firstâ€ï¼Œfc_model è¿˜éœ€è¦ä¿®æ”¹ä¸€ä¸‹æ ¼å¼ï¼Œå› ä¸ºVGG16æºç æ˜¯ä»¥ â€œchannels_lastâ€å®šä¹‰çš„ï¼Œæ‰€ä»¥éœ€è¦è½¬æ¢ä¸€ä¸‹è¾“å‡ºæ ¼å¼ï¼Œ

 maxpool = model.get_layer(name='block5_pool')
 # model.get_layer()ä¾æ®å±‚åæˆ–ä¸‹æ ‡è·å¾—å±‚å¯¹è±¡
 shape = maxpool.output_shape[1:]
 # è·å–block5_poolå±‚è¾“å‡ºçš„æ•°æ®æ ¼å¼
 dense = model.get_layer(name='fc1')
 layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')
ã€€ã€€å…¶ä¸­layer_utils.convert_dense_weights_data_formatçš„ä½œç”¨å¾ˆç‰¹æ®Šï¼Œå®˜æ–¹æ–‡æ¡£ä¸­æ²¡æœ‰è¯´æ˜ï¼Œæœ¬è´¨ä¸Šç”¨æ¥ä¿®æ”¹æ•°æ®æ ¼å¼ï¼Œå› ä¸ºå±‚ä¸­æœ‰ Flattenå±‚æŠŠæ•°æ®æ ¼å¼æ¢äº†ï¼Œæ‰€ä»¥éœ€è¦ä¿®æ”¹ä¸€ä¸‹ã€‚

5.2 åºåˆ—å¼
ã€€ã€€æœ¬èŠ‚èŠ‚é€‰è‡ªKerasä¸­æ–‡æ–‡æ¡£ã€ŠCNNçœ¼ä¸­çš„ä¸–ç•Œï¼šåˆ©ç”¨Kerasè§£é‡ŠCNNçš„æ»¤æ³¢å™¨ã€‹ï¼ˆhttps://keras-cn.readthedocs.io/en/latest/blog/cnn_see_world/ï¼‰

ã€€ã€€å·²è®­ç»ƒå¥½VGG16å’ŒVGG19æ¨¡å‹çš„æƒé‡ï¼š

å›½å¤–ï¼šhttps://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3
å›½å†…ï¼šhttp://files.heuritech.com/weights/vgg16_weights.h5
ã€€ã€€å‰é¢æ˜¯VGG16æ¶æ„çš„å‡½æ•°å¼æ¨¡å‹çš„ç»“æ„ï¼Œé‚£ä¹ˆåœ¨å®˜æ–¹æ–‡æ¡£è¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œä¹Ÿæœ‰VGG16æ¶æ„çš„åºåˆ—å¼ï¼Œéƒ½æ‹¿æ¥æ¯”å¯¹ä¸€ä¸‹æ¯”è¾ƒå¥½ã€‚

ã€€ã€€é¦–å…ˆæˆ‘ä»¬åœ¨Kerasä¸­å®šä¹‰ VGG ç½‘ç»œçš„ç»“æ„

from keras.models import Sequential
from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D

img_width, img_height = 128, 128

# build the VGG16 network
model = Sequential()
model.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, img_width, img_height)))
first_layer = model.layers[-1]
# this is a placeholder tensor that will contain our generated images
input_img = first_layer.input

# build the rest of the network
model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))
model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))
model.add(MaxPooling2D((2, 2), strides=(2, 2)))

model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))
model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))
model.add(MaxPooling2D((2, 2), strides=(2, 2)))

model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))
model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))
model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))
model.add(MaxPooling2D((2, 2), strides=(2, 2)))

model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))
model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))
model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))
model.add(MaxPooling2D((2, 2), strides=(2, 2)))

model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))
model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))
model.add(ZeroPadding2D((1, 1)))
model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))
model.add(MaxPooling2D((2, 2), strides=(2, 2)))

# get the symbolic outputs of each "key" layer (we gave them unique names).
layer_dict = dict([(layer.name, layer) for layer in model.layers])
ã€€ã€€ä»ä½¿ç”¨ Convolution2D æ¥çœ‹ï¼Œæ˜¯æ¯”è¾ƒæ—©çš„ç‰ˆæœ¬å†™çš„ã€‚

Sequentialæ¨¡å‹å¦‚ä½•éƒ¨åˆ†layerè½½å…¥æƒé‡

ã€€ã€€ä¸‹é¢æˆ‘ä»¬å°†é¢„è®­ç»ƒå¥½çš„æƒé‡è½½å…¥æ¨¡å‹ï¼Œä¸€èˆ¬è€Œè¨€æˆ‘ä»¬å¯ä»¥é€šè¿‡ Model.load_weights()è½½å…¥ï¼Œä½†è¿™ç§åŠæ³•æ˜¯è½½å…¥å…¨éƒ¨çš„æƒé‡ï¼Œå¹¶ä¸é€‚ç”¨ã€‚

ã€€ã€€ä¹‹å‰æ‰€çœ‹åˆ°çš„ no_top æ¨¡å‹å°±æ˜¯ç”¨æ¥åº”ä»˜æ­¤æ—¶çš„ï¼Œè¿™é‡Œæˆ‘ä»¬åªè½½å…¥ä¸€éƒ¨åˆ†å‚æ•°ï¼Œç”¨çš„æ—¶ set_weights() å‡½æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ‰‹å·¥è½½å…¥ï¼š

import h5py

weights_path = '.../vgg16_weights.h5'

f = h5py.File(weights_path)
for k in range(f.attrs['nb_layers']):
    if k >= len(model.layers):
        break
    g = f['layer_{}'.format(k)]
    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]
    model.layers[k].set_weights(weights)
f.close()
print('Model loaded.')
ã€€ã€€ä½†æ˜¯ ï¼Œè½½å…¥çš„.h5æ¨¡å‹ï¼Œæ²¡æœ‰å±æ€§nb_layersï¼Œä¼šæŠ¥é”™ï¼Œå¦‚ä¸‹ï¼š



 

6ï¼Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹Mobilenetç½‘ç»œè®­ç»ƒ
6.1 å¯¼å…¥é¢„è®­ç»ƒæƒé‡ä¸ç½‘ç»œæ¡†æ¶
ã€€ã€€é¦–å…ˆä¸‹è½½æ¨¡å‹ï¼šhttps://github.com/fchollet/deep-learning-models/releases

ã€€ã€€å½“ç„¶ä¹Ÿå¯ä»¥ä¸ä¸‹è½½ï¼Œç›´æ¥å¯¼å…¥å³å¯ï¼Œæˆ‘ä¸‹è½½ä¸‹æ¥ä¸ºäº†æ–¹ä¾¿å¿«æ·ã€‚ä¸‹è½½ååˆ™éœ€è¦ä¿®æ”¹éƒ¨åˆ†æºç ã€‚

WEIGHTS_PATH = '/data/mobilenet_5_0_224_tf.h5'
WEIGHTS_PATH_NO_TOP = '/data/mobilenet_5_0_224_tf_no_top.h5'

from keras.applications.mobilenet import MobileNet

model = MobileNet(include_top=False, weights='imagenet')
 ã€€ã€€å…¶ä¸­ WEIGHTS_PATH_NO_TOP å°±æ˜¯å»æ‰äº†å…¨è¿æ¥å±‚ï¼Œå¯ä»¥ç”¨å®ƒç›´æ¥æå– bottleneckçš„ç‰¹å¾ã€‚

6.2  æå–å›¾ç‰‡çš„ bottleneckç‰¹å¾
ã€€ã€€æˆ‘ä»¬ä»ç„¶é‡‡å–ä¸Šä¸€ç¯‡æ–‡ç« ä¸­ä½¿ç”¨çš„æ•°æ®ï¼Œå¦‚æœéœ€è¦çš„è¯ï¼Œå¯ä»¥å»ä¸Šä¸€ç¯‡æ–‡ç« ä¸­çš„è¿æ¥å»æ‰¾ã€‚

æˆ‘çš„Kerasä½¿ç”¨æ€»ç»“ï¼ˆ3ï¼‰â€”â€”åˆ©ç”¨bottleneck featuresè¿›è¡Œå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹VGG16
ã€€ã€€åªä¸è¿‡è¿™æ¬¡å°è¯•ä½¿ç”¨mobilenetçš„é¢„è®­ç»ƒæ¨¡å‹æå–å›¾ç‰‡ç‰¹å¾ï¼Œè€Œä¸æ˜¯VGGæ¨¡å‹ï¼Œæˆ‘æƒ³çœ‹çœ‹Mobilenetçš„æ•ˆæœå¦‚ä½•ï¼Œé¡ºä¾¿çœ‹çœ‹è‡ªå·±æŒæ¡äº†æ²¡æœ‰ã€‚



ã€€  å…¶å®ä»£ç å’Œä¸Šä¸€èŠ‚çš„å¤§åŒå°å¼‚ï¼Œåªä¸è¿‡è¿™æ¬¡æˆ‘ä½¿ç”¨çš„æ›´åŠ å¨´ç†Ÿäº†ï¼Œè€Œä¸”æœ‰äº›å‚æ•°çš„æ„æ€ä¹Ÿæ›´åŠ æ˜ç¡®äº†ï¼Œè€Œä¸”æœ‰äº›å‚æ•°è¿˜æ˜¯ä¸è¦å†™æ­»çš„å¥½ï¼Œå…·ä½“å¯ä»¥å‚è€ƒæˆ‘çš„ä»£ç ã€‚

ã€€ã€€å®Œæ•´ä»£ç å¦‚ä¸‹ï¼š

from keras.applications.mobilenet import MobileNet
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
import os
import keras
import tensorflow as tf
from keras.backend.tensorflow_backend import set_session

os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.3
set_session(tf.Session(config=config))


def save_bottleneck_features():
    model = MobileNet(include_top=False, weights='imagenet', input_shape=(150, 150, 3))
    print('load model ok')
    datagen = ImageDataGenerator(rescale=1. / 255)

    # train set image generator
    train_generator = datagen.flow_from_directory(
        '/data/lebron/data/mytrain',
        target_size=(150, 150),
        batch_size=batch_size,
        class_mode=None,
        shuffle=False
    )

    # test set image generator
    test_generator = datagen.flow_from_directory(
        '/data/lebron/data/mytest',
        target_size=(150, 150),
        batch_size=batch_size,
        class_mode=None,
        shuffle=False
    )

    # load weight
    model.load_weights(WEIGHTS_PATH_NO_TOP)
    print('load weight ok')
    # get bottleneck feature
    bottleneck_features_train = model.predict_generator(train_generator, 10)
    np.save(save_train_path, bottleneck_features_train)

    bottleneck_features_validation = model.predict_generator(test_generator, 2)
    np.save(save_test_path, bottleneck_features_validation)
    

def train_fine_tune():
    # load bottleneck features
    train_data = np.load(save_train_path)
    train_labels = np.array(
        [0] * 100 + [1] * 100 + [2] * 100 + [3] * 100 + [4] * 100
    )
    validation_data = np.load(save_test_path)
    validation_labels = np.array(
        [0] * 20 + [1] * 20 + [2] * 20 + [3] * 20 + [4] * 20
    )
    # set labels
    train_labels = keras.utils.to_categorical(train_labels, 5)
    validation_labels = keras.utils.to_categorical(validation_labels, 5)

    model = Sequential()
    model.add(Flatten(input_shape=train_data.shape[1:]))
    model.add(Dense(256, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(5, activation='softmax'))

    model.compile(loss='categorical_crossentropy', 
                  optimizer='rmsprop',
                  metrics=['accuracy'])

    model.fit(train_data, train_labels,
              nb_epoch=500, batch_size=25,
              validation_data=(validation_data, validation_labels))


if __name__ == '__main__':
    WEIGHTS_PATH = '/data/model/mobilenet_1_0_224_tf.h5'
    WEIGHTS_PATH_NO_TOP = '/data/model/mobilenet_1_0_224_tf_no_top.h5'
    save_train_path = '/data/bottleneck_features_train.npy'
    save_test_path = '/data/bottleneck_features_validation.npy'
    batch_size = 50
    save_bottleneck_features()
    train_data = np.load(save_train_path)
    validation_data = np.load(save_test_path)
    print(train_data.shape, validation_data.shape)
    train_fine_tune()
    print('game over')
 ã€€ã€€è®­ç»ƒçš„ç»“æœå°±ä¸å±•ç¤ºäº†ï¼Œè¿™é‡Œè¯´ä¸€ä¸‹å‡†ç¡®ç‡æ˜¯ç™¾åˆ†ä¹‹å…«åï¼Œlossæœ‰ç‚¹é«˜ï¼Œé™ä¸ä¸‹æ¥ï¼Œæˆ‘ä¼šå†å­¦ä¹ ç ”ç©¶çš„ã€‚                
                
                
                """)
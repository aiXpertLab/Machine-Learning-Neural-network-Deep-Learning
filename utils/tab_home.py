import streamlit as st

def home_main_contents():
    st.image('./images/dl/compare.png')
    st.write("""
             
1843å¹´ï¼ŒåŸƒè¾¾â€¢ æ´›å¤«è±æ–¯ä¼¯çˆµå¤«äººå¯¹è¿™é¡¹å‘æ˜è¯„è®ºé“ï¼šâ€œåˆ†ææœºè°ˆä¸ä¸Šèƒ½åˆ›é€ ä»€ä¹ˆä¸œè¥¿ã€‚å®ƒåªèƒ½å®Œæˆæˆ‘ä»¬å‘½ä»¤å®ƒåšçš„ä»»ä½•äº‹æƒ…â€¦â€¦å®ƒçš„èŒè´£æ˜¯å¸®åŠ©æˆ‘ä»¬å»
å®ç°æˆ‘ä»¬å·²çŸ¥çš„äº‹æƒ…ã€‚â€

éšåï¼Œäººå·¥æ™ºèƒ½å…ˆé©±é˜¿å…°â€¢ å›¾çµåœ¨å…¶1950 å¹´å‘è¡¨çš„å…·æœ‰é‡Œç¨‹ç¢‘æ„ä¹‰çš„è®ºæ–‡â€œè®¡ç®—æœºå™¨å’Œæ™º
èƒ½â€a ä¸­ï¼Œå¼•ç”¨äº†ä¸Šè¿°è¯„è®ºå¹¶å°†å…¶ç§°ä¸ºâ€œæ´›å¤«è±æ–¯ä¼¯çˆµå¤«äººçš„å¼‚è®®â€ã€‚å›¾çµåœ¨è¿™ç¯‡è®ºæ–‡ä¸­ä»‹ç»äº†å›¾
çµæµ‹è¯•ä»¥åŠæ—¥åäººå·¥æ™ºèƒ½æ‰€åŒ…å«çš„é‡è¦æ¦‚å¿µã€‚åœ¨å¼•è¿°åŸƒè¾¾â€¢ æ´›å¤«è±æ–¯ä¼¯çˆµå¤«äººçš„åŒæ—¶ï¼Œå›¾çµè¿˜
æ€è€ƒäº†è¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼šé€šç”¨è®¡ç®—æœºæ˜¯å¦èƒ½å¤Ÿå­¦ä¹ ä¸åˆ›æ–°ï¼Ÿä»–å¾—å‡ºçš„ç»“è®ºæ˜¯â€œèƒ½â€ã€‚
æœºå™¨å­¦ä¹ çš„æ¦‚å¿µå°±æ¥è‡ªäºå›¾çµçš„è¿™ä¸ªé—®é¢˜ï¼šå¯¹äºè®¡ç®—æœºè€Œè¨€ï¼Œé™¤äº†â€œæˆ‘ä»¬å‘½ä»¤å®ƒåšçš„ä»»ä½•
äº‹æƒ…â€ä¹‹å¤–ï¼Œå®ƒèƒ½å¦è‡ªæˆ‘å­¦ä¹ æ‰§è¡Œç‰¹å®šä»»åŠ¡çš„æ–¹æ³•ï¼Ÿè®¡ç®—æœºèƒ½å¦è®©æˆ‘ä»¬å¤§åƒä¸€æƒŠï¼Ÿå¦‚æœæ²¡æœ‰ç¨‹
åºå‘˜ç²¾å¿ƒç¼–å†™çš„æ•°æ®å¤„ç†è§„åˆ™ï¼Œè®¡ç®—æœºèƒ½å¦é€šè¿‡è§‚å¯Ÿæ•°æ®è‡ªåŠ¨å­¦ä¼šè¿™äº›è§„åˆ™ï¼Ÿ
å›¾çµçš„è¿™ä¸ªé—®é¢˜å¼•å‡ºäº†ä¸€ç§æ–°çš„ç¼–ç¨‹èŒƒå¼ã€‚åœ¨ç»å…¸çš„ç¨‹åºè®¾è®¡ï¼ˆå³ç¬¦å·ä¸»ä¹‰äººå·¥æ™ºèƒ½çš„èŒƒ
å¼ï¼‰ä¸­ï¼Œäººä»¬è¾“å…¥çš„æ˜¯è§„åˆ™ï¼ˆå³ç¨‹åºï¼‰å’Œéœ€è¦æ ¹æ®è¿™äº›è§„åˆ™è¿›è¡Œå¤„ç†çš„æ•°æ®ï¼Œç³»ç»Ÿè¾“å‡ºçš„æ˜¯ç­”æ¡ˆ
ï¼ˆè§å›¾1-2ï¼‰ã€‚åˆ©ç”¨æœºå™¨å­¦ä¹ ï¼Œäººä»¬è¾“å…¥çš„æ˜¯æ•°æ®å’Œä»è¿™äº›æ•°æ®ä¸­é¢„æœŸå¾—åˆ°çš„ç­”æ¡ˆï¼Œç³»ç»Ÿè¾“å‡ºçš„æ˜¯
è§„åˆ™ã€‚è¿™äº›è§„åˆ™éšåå¯åº”ç”¨äºæ–°çš„æ•°æ®ï¼Œå¹¶ä½¿è®¡ç®—æœºè‡ªä¸»ç”Ÿæˆç­”æ¡ˆã€‚
             
äººå·¥æ™ºèƒ½è¯ç”Ÿäº20 ä¸–çºª50 å¹´ä»£ï¼Œå½“æ—¶è®¡ç®—æœºç§‘å­¦è¿™ä¸€æ–°å…´é¢†åŸŸçš„å°‘æ•°å…ˆé©±å¼€å§‹æå‡ºç–‘é—®ï¼š
è®¡ç®—æœºæ˜¯å¦èƒ½å¤Ÿâ€œæ€è€ƒâ€ï¼Ÿæˆ‘ä»¬ä»Šå¤©ä»åœ¨æ¢ç´¢è¿™ä¸€é—®é¢˜çš„ç­”æ¡ˆã€‚äººå·¥æ™ºèƒ½çš„ç®€æ´å®šä¹‰å¦‚ä¸‹ï¼šåŠª
åŠ›å°†é€šå¸¸ç”±äººç±»å®Œæˆçš„æ™ºåŠ›ä»»åŠ¡è‡ªåŠ¨åŒ–ã€‚å› æ­¤ï¼Œäººå·¥æ™ºèƒ½æ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„é¢†åŸŸï¼Œä¸ä»…åŒ…æ‹¬æœºå™¨
å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ ï¼Œè¿˜åŒ…æ‹¬æ›´å¤šä¸æ¶‰åŠå­¦ä¹ çš„æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œæ—©æœŸçš„å›½é™…è±¡æ£‹ç¨‹åºä»…åŒ…å«ç¨‹åºå‘˜ç²¾
å¿ƒç¼–å†™çš„ç¡¬ç¼–ç è§„åˆ™ï¼Œå¹¶ä¸å±äºæœºå™¨å­¦ä¹ ã€‚åœ¨ç›¸å½“é•¿çš„æ—¶é—´å†…ï¼Œè®¸å¤šä¸“å®¶ç›¸ä¿¡ï¼Œåªè¦ç¨‹åºå‘˜ç²¾
å¿ƒç¼–å†™è¶³å¤Ÿå¤šçš„æ˜ç¡®è§„åˆ™æ¥å¤„ç†çŸ¥è¯†ï¼Œå°±å¯ä»¥å®ç°ä¸äººç±»æ°´å¹³ç›¸å½“çš„äººå·¥æ™ºèƒ½ã€‚è¿™ä¸€æ–¹æ³•è¢«ç§°
ä¸ºç¬¦å·ä¸»ä¹‰äººå·¥æ™ºèƒ½ï¼ˆ`symbolic AI`ï¼‰ï¼Œä»20 ä¸–çºª50 å¹´ä»£åˆ°80 å¹´ä»£æœ«æ˜¯äººå·¥æ™ºèƒ½çš„ä¸»æµèŒƒå¼ã€‚
åœ¨20 ä¸–çºª80 å¹´ä»£çš„ä¸“å®¶ç³»ç»Ÿï¼ˆ`expert system`ï¼‰çƒ­æ½®ä¸­ï¼Œè¿™ä¸€æ–¹æ³•çš„çƒ­åº¦è¾¾åˆ°äº†é¡¶å³°ã€‚

è™½ç„¶ç¬¦å·ä¸»ä¹‰äººå·¥æ™ºèƒ½é€‚åˆç”¨æ¥è§£å†³å®šä¹‰æ˜ç¡®çš„é€»è¾‘é—®é¢˜ï¼Œæ¯”å¦‚ä¸‹å›½é™…è±¡æ£‹ï¼Œä½†å®ƒéš¾ä»¥ç»™
å‡ºæ˜ç¡®çš„è§„åˆ™æ¥è§£å†³æ›´åŠ å¤æ‚ã€æ¨¡ç³Šçš„é—®é¢˜ï¼Œæ¯”å¦‚å›¾åƒåˆ†ç±»ã€è¯­éŸ³è¯†åˆ«å’Œè¯­è¨€ç¿»è¯‘ã€‚äºæ˜¯å‡ºç°
äº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥æ›¿ä»£ç¬¦å·ä¸»ä¹‰äººå·¥æ™ºèƒ½ï¼Œè¿™å°±æ˜¯æœºå™¨å­¦ä¹ ï¼ˆ`machine learning`ï¼‰ã€‚
             
             
             """)
    st.image("./images/ai.png")
    main_contents="""
In basic terms, the goal of using AI is to make computers think as humans do. 
For example, to solve a sudoku problem, you can:
- Using Python to write conditional statements and check the constraints to see if you can place a number in each position. 
- Machine learning (ML) and deep learning (DL) are also approaches to solving problems.

The difference between these techniques and a Python script is that ML and DL use training data instead of hard-coded rules, but all of them can be used to solve problems using AI. 

#### ğŸ“šMachine Learning
Machine learning is a technique in which you train the system to solve a problem instead of explicitly programming the rules. 
Getting back to the sudoku example in the previous section, to solve the problem using machine learning, you would gather data from solved sudoku games and train a statistical model. 
Statistical models are mathematically formalized ways to approximate the behavior of a phenomenon.

A common machine learning task is **supervised learning**, in which you have a dataset with inputs and known outputs. 
The task is to use this dataset to train a model that predicts the correct outputs based on the inputs. 

The goal of supervised learning tasks is to make predictions for new, unseen data. 
To do that, you assume that this unseen data follows a probability distribution similar to the distribution of the training dataset. 
If in the future this distribution changes, then you need to train your model again using the new training dataset.

#### ğŸ“„Features Enginerring
Another name for input data is `feature`, and feature engineering is the process of extracting features from raw data. 

Prediction problems become harder when you use different kinds of data as inputs. 
What if you want to train a model to predict the sentiment in a sentence? 
Or what if you have an image, and you want to know whether it depicts a cat?


An example of a feature engineering technique is `lemmatization`, in which you remove the inflection from words in a sentence. 
If youâ€™re using arrays to store each word of a corpus, then by applying lemmatization, you end up with a less-sparse matrix. 
This can increase the performance of some machine learning algorithms. Creating features using a `bag-of-words model`.

#### ğŸ”Deep Learning
Deep learning is a technique in which you let the neural network figure out by itself which features are important instead of applying feature engineering techniques. 
This means that, with deep learning, you can bypass the feature engineering process.

Not having to deal with feature engineering is good because the process gets harder as the datasets become more complex. 
For example, how would you extract the data to predict the mood of a person given a picture of her face? 
With neural networks, you donâ€™t need to worry about it because the networks can learn the features by themselves. 

Think of AI as the entire field of transportation.
Machine learning would be like cars in general.
Deep learning would be a specific type of car, like a sports car.
Neural networks would be the engine of the car.
Large language models would be a specific type of car designed for racing, built on a powerful engine.

            """
    st.markdown(main_contents)
    st.image("./images/aihistory.png")
    



def st_text_preprocessing_contents():
    st.markdown("""
        - Normalize Text
        - Remove Unicode Characters
        - Remove Stopwords
        - Perform Stemming and Lemmatization
    """)    

def st_load_ML():
    st.image("./images/mlpipeline.png")


def st_kaldi():
    contents="""
        ### ğŸš€ Kaldi ğŸ¨
        
        A paper is stored in data.
        https://eleanorchodroff.com/tutorial/kaldi/training-overview.html
        

        TensorFlow APIs are arranged hierarchically, with the high-level APIs built on the low-level APIs. 
        Machine learning researchers use the low-level APIs to create and explore new machine learning algorithms.
        We will use a high-level API named `tf.keras` to define and train machine learning models and to make predictions. 
        tf.keras is the TensorFlow variant of the open-source Keras API.

        ### ğŸ“„Key FeaturesğŸ“š:
        -  ğŸ” No Coding Required: Say goodbye to developer fees and lengthy website updates. Store Sparkâ€™s user-friendly API ensures a smooth integration process.
        -  ğŸ“° Empower Your Business: Offer instant customer support, improve lead generation, and boost conversion rates â€” all with minimal setup effort.
        -  ğŸ¨ Seamless Integration: Maintain your existing website design and user experience. Store Spark seamlessly blends in, providing a unified customer journey.
        """
    st.markdown(contents)
    st.image("./images/kalditf.png")
    st.image("./images/kaldi.png")

def home_dev():
    st.markdown('### Python')
    import scipy, numpy, matplotlib, pandas, statsmodels, sklearn, PIL
    st.text('scipy: %s' % scipy.__version__)
    st.text('numpy: %s' % numpy.__version__)
    st.text('matplotlib: %s' % matplotlib.__version__)
    st.text('pandas: %s' % pandas.__version__)
    st.text('statsmodels: %s' % statsmodels.__version__)
    st.text('sklearn: %s' % sklearn.__version__)
    st.text(f'PIL: {PIL.__version__}' )
    
    st.markdown('### Deep Learning')
    import tensorflow, keras
    st.text('TF: %s' % tensorflow.__version__)
    st.text('Keras: %s' % keras.__version__)
